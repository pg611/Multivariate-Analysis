---
title: "Social_Media_Final_Analysis"
author: "pg611@scarletmail.rutgers.edu"
date: "2024-04-29"
output: html_document
---

```{r }
library(MASS)
library(ggplot2)
library(memisc)
library(ROCR)
library(dplyr)
library(klaR)
library(memisc)
library(ggplot2)
library(corrplot)
library(factoextra)
library(psych)
library(NbClust)
library(caTools)
library(magrittr)
library(pROC)
library(caret)


sc_dataset <- read.csv("/Users/parul/OneDrive/Desktop/MVA/Midterm_new.csv", row.names=1)
str(sc_dataset)
```

# DATA COLLECTION :

* The data is collected from a class of 21 students who have reported their usage of social media.
* The data has 12 columns and 22 rows in total.
* The data is cumulated for each student. 


# Data Dictionary :

* Dataset ID: A unique identifier for each student's data entry.
* Instagram Usage: The duration of usage of the Instagram app.
* LinkedIn Usage: The duration of usage of the LinkedIn app.
* Snapchat Usage: The duration of usage of the Snapchat app.
* Twitter Usage: The duration of usage of the Twitter app.
* Whatsapp Usage: The duration of usage of the WhatsApp app.
* Youtube Usage: The duration of usage of the YouTube app.
* OTT Usage: The duration of usage of Over-the-Top media services.
* Reddit Usage: The duration of usage of the Reddit app.
* Trouble Falling Asleep: Indicates whether the student reported having trouble falling asleep (0: No, 1: Yes).
* Mood Productivity: A subjective measure of the student's mood and productivity level.(0: Bad, 1: Good)
* Tiredness upon Waking Up in the Morning: Indicates the level of tiredness the student reported upon waking up in the morning (0: Low, 1: High).



# QUESTIONS and HYPOTHESIS Questions :

* Based on the given variables, can we classify if the student is facing problem while falling asleep or not, which can cause health issues because of social media usage.
* Based on the given variables, can we predict if the student is facing problem while falling asleep or not, which can cause health issues because of social media usage.

# Hypothesis :

* We can predict if the student is getting affected or student is facing problem while falling asleep or not based on the time they have spent on the individual social media apps.


# Analysis and Visualization :

```{r }
str(sc_dataset)
summary(sc_dataset)
stars(sc_dataset)
```


```{r }
correlation_matrix <- cor(sc_dataset[,1:11])
correlation_matrix

corrplot(cor(sc_dataset), type = "upper", method = "color")

```

• The correlation matrix shows us a correlation between the columns in both cases. 

• Hence, Principal Component Analysis (PCA) can be used to reduce the number of columns for the analysis. 

# PCA 
```{r }

# PCA

sc_dataset_pca <- prcomp(sc_dataset[,1:8],scale=TRUE) 
sc_dataset_pca

summary(sc_dataset_pca)

fviz_eig(sc_dataset_pca, addlabels = TRUE)
#plot(sc_dataset, xlab = "Component number", ylab = "Component variance", main = "Scree diagram")
```

• The scree diagram shows us that sum of the first 2 principal components is less than 70%.

• So, we cannot move forward using PCA for column reduction. 

• We now move on to check EFA for this dataset.



```{r}

fviz_pca_var(sc_dataset_pca,col.var = "cos2",
             gradient.cols = c("#FFCC00", "#CC9933", "#660033", "#330033"),
             repel = TRUE)
```

# FACTOR ANALYSIS :

```{r}

fit.pc <- principal(sc_dataset[,1:8], nfactors=4, rotate="varimax") 
fit.pc



fa.diagram(fit.pc) 

vss(sc_dataset[,1:8])

```

Defining the factors Obtained-
RC1 : Content Sharing Platforms

• Both Twitter and Reddit serve as platforms for social networking, allowing users to connect with others, share content, and engage in discussions.

RC2 : Popular Social Media

• Snapchat, LinkedIn, Instagram are popular all over the world. 

• LinkedIn is used for professional purposes. Snapchat is used for chatting and 
Instagram is used for posting photos and videos. 

RC3 : Chatting and Entertainment

• Whatsapp & OTT are famous all over the world. 

• Both are used for chatting and entertainment.

RC4 : Learning Platform

• Youtube is used for both learning and entertainment. 


# CLUSTERING:

```{r}
# CLUSTERING

efa_data <- as.data.frame(fit.pc$scores)
efa_data


matstd_sm <- scale(efa_data)



res.hc <- matstd_sm %>% scale() %>% dist(method = "euclidean") %>%
  hclust(method = "ward.D2")

res.nbclust <- matstd_sm %>% scale() %>% NbClust(distance = "euclidean", min.nc = 3, max.nc = 13, method = "complete", index ="all") 

km.res <- kmeans(matstd_sm, 5, nstart = 10)

fviz_cluster(km.res, data = matstd_sm,
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal())

dist.sc_dataset <- dist(matstd_sm, method="euclidean")



fviz_dend(res.hc, k = 5, # Cut in four groups
          cex = 0.5, # label size
          k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
          color_labels_by_k = TRUE, # color labels by groups
          rect = TRUE # Add rectangle around groups
)


Clustered <- ifelse(km.res$cluster > 1.5, "No Trouble in Sleep", "Trouble in sleep")
Actual <- ifelse(sc_dataset$Trouble_falling_asleep == 1, "Trouble Sleep", "No trouble in sleep")
confusion_mat <- table(Clustered, Actual)
confusion_mat

accuracy <- sum(diag(confusion_mat)) / sum(confusion_mat)
precision <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
recall <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
cat("Accuracy:", round(accuracy, 3), "\n")
cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")




```

• We can see that the confusion matrix shows the clustering is done in a way where almost all the users are not feeling any trouble in falling asleep .

• This shows that we cannot classify our data into trouble falling asleep yes or no based on the variables given.

• The precision is obtained to be 92% which is not so bad.


# REGRESSION :

```{r}
wdbc <- read.csv("/Users/parul/OneDrive/Desktop/MVA/Midterm_new.csv")
features <- c("Instagram", "LinkedIn", "Snapchat", "Twitter", "Whatsapp", "Youtube", "OTT", "Reddit", "Trouble_sleep", "Mood", "Tired_morning")
names(wdbc) <- c("ID", "Instagram", "LinkedIn", "Snapchat", "Twitter", "Whatsapp", "Youtube", "OTT", "Reddit", "Trouble_sleep", "Mood", "Tired_morning")
wdbc<- wdbc
wdbc.data <- as.matrix(wdbc[,c(2:9)])
row.names(wdbc.data) <- wdbc$ID

```


# DATA SPLITTING :
```{r}
wdbc_raw <- cbind(wdbc.data, as.numeric(as.factor(wdbc$Trouble_sleep))-1)
colnames(wdbc_raw)[9] <- "TroubleInSleep"
smp_size_raw <- floor(0.70 * nrow(wdbc_raw))
train_ind_raw <- sample(nrow(wdbc_raw), size = smp_size_raw)
train_raw.df <- as.data.frame(wdbc_raw[train_ind_raw, ])
test_raw.df <- as.data.frame(wdbc_raw[-train_ind_raw, ])

```


Now divided the dataset into training and testing data for regression analysis.
We consider the training and testing data with a 70-30 split.



# MULTIPLE REGRESSION :

* Multiple regression is a statistical technique used to understand the relationship between one dependent variable and two or more independent variables. 

* It aims to predict the value of the dependent variable based on the values of the independent variables.

```{r}
# MULTIPLE REGRESSION

x_sm <- cbind(train_ind_raw,train_raw.df[, -9])

fit <- lm(TroubleInSleep ~ ., data = train_raw.df) 

summary(fit)
coefficients(fit)
residuals(fit)
probabilities_sm2 <- predict(fit, newdata = test_raw.df, type = "response")

predicted_sm2 <- ifelse(probabilities_sm2 > 0.5, "Yes", "No")
actual_sm <- ifelse(test_raw.df$TroubleInSleep == 1, "Yes", "No")
confusion_sm2 <- table(predicted_sm2, actual_sm)
confusion_sm2

threshold<-0.5
predicted <- predict(fit, newdata = test_raw.df)

predicted_category <- ifelse(predicted > threshold, "No Trouble in Sleep", "Trouble in sleep")

# Convert actual values to binary categories
actual_category <- ifelse(test_raw.df$TroubleInSleep == 1, "No Trouble in sleep", "Trouble in sleep")

# Create a confusion matrix
confusion_mat <- table(predicted_category, actual_category)

# Calculate accuracy
accuracy <- sum(diag(confusion_mat)) / sum(confusion_mat)
accuracy

roc_sm <- roc(test_raw.df$TroubleInSleep, probabilities_sm2)
auc_sm <- auc(roc_sm)

ggroc(roc_sm, color = "blue", legacy.axes = TRUE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "False Positive Rate", y = "True Positive Rate",
       title = paste("ROC Curve (AUC = ", round(auc_sm, 2), ")")) +
  annotate("text", x = 0.5, y = 0.5, label = paste0("AUC = ", round(auc_sm, 2)))



```

The regression summary shows that we have significant variables that affect the output variable.

The regression summary shows that we have significant variables that affect the output variable.


# LOGISTIC REGRESSION :

* Logistic regression is a statistical method used for binary classification problems. It predicts the probability that a given observation belongs to one of two classes.
* It models the relationship between a binary dependent variable and one or more independent variables.

We can now check how the logistic regression-

```{r}
# Logistic Regression

logistic_sm <- glm(TroubleInSleep ~ ., data = train_raw.df, family = 'binomial')
summary(logistic_sm)

predicted.data <- data.frame(probability.of.hd=logistic_sm$fitted.values,TroubleInSleep=train_raw.df$TroubleInSleep)
predicted.data <- predicted.data[order(predicted.data$probability.of.hd, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)

ggplot(data=predicted.data, aes(x=rank, y=probability.of.hd)) +
  geom_point(aes(color=TroubleInSleep), alpha=1, shape=4, stroke=2) +
  xlab("Index") +
  ylab("Predicted probability of getting in sleeping")
probabilities_sm2 <- predict(logistic_sm, newdata = test_raw.df, type = "response")

predicted_sm2 <- ifelse(probabilities_sm2 > 0.5, "Yes", "No")
actual_sm <- ifelse(test_raw.df$TroubleInSleep == 1, "Yes", "No")
confusion_sm2 <- table(predicted_sm2, actual_sm)
confusion_sm2
accuracy2 <- sum(diag(confusion_sm2)) / sum(confusion_sm2)
precision2 <- confusion_sm2[2, 2] / sum(confusion_sm2[, 2])
recall2 <- confusion_sm2[2, 2] / sum(confusion_sm2[2, ])
cat("Accuracy:", round(accuracy2, 3), "\n")
cat("Precision:", round(precision2, 3), "\n")
cat("Recall:", round(recall2, 3), "\n")
probabilities <- predict(logistic_sm, newdata = test_raw.df, type = "response")

roc_sm <- roc(test_raw.df$TroubleInSleep, probabilities_sm2)
auc_sm <- auc(roc_sm)

ggroc(roc_sm, color = "blue", legacy.axes = TRUE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "False Positive Rate", y = "True Positive Rate",
       title = paste("ROC Curve (AUC = ", round(auc_sm, 2), ")")) +
  annotate("text", x = 0.5, y = 0.5, label = paste0("AUC = ", round(auc_sm, 2)))
```

These visualizations provide valuable insights into the logistic regression model's performance by showcasing Accuracy and ROC Curve of the model.



# DISCRIMINANT :

* Discriminant analysis is a statistical method used for classification tasks that involve identifying which category or group a new observation belongs to based on one or more predictor variables (features).

```{r}

# DISCRIMINANT MODEL
wdbc_raw.lda <- lda(formula = TroubleInSleep ~ ., data = train_raw.df)
wdbc_raw.lda
summary(wdbc_raw.lda)
plot(wdbc_raw.lda)
predictions <- predict(wdbc_raw.lda, newdata = test_raw.df)
predicted_classes <- predictions$class
accuracy2 <- mean(predicted_classes == test_raw.df$TroubleInSleep)
accuracy2
wdbc_raw.lda.predict_train <- predict(wdbc_raw.lda, newdata = train_raw.df)
y<-wdbc_raw.lda.predict_train$class
wdbc_raw.lda.predict_train$x
table(y,train_raw.df$TroubleInSleep)
wdbc_raw.lda.predict_test <- predict(wdbc_raw.lda, newdata = test_raw.df)
y<-wdbc_raw.lda.predict_test$class
wdbc_raw.lda.predict_test$x
table(y,test_raw.df$TroubleInSleep)
wdbc_raw.lda.predict.posteriors <- as.data.frame(wdbc_raw.lda.predict_test$posterior)
pred <- prediction(wdbc_raw.lda.predict.posteriors[,2], test_raw.df$TroubleInSleep)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
plot(roc.perf)
abline(a=0, b= 1)
text(x = .25, y = .65 ,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
plot(wdbc_raw.lda, col = as.integer(train_raw.df$TroubleInSleep))

  

```

The accuracy provides a clear visualization of how well the model performs overall. 

The ROC curve offers deeper insights into the model's sensitivity and specificity

# CONCLUSION : 

Regression Summary-

The logistic regression model yielded the highest accuracy and demonstrated superior performance, as evidenced by its ROC curve. Logistic regression excelled in accurately predicting outcomes, particularly in distinguishing between troubled and non-troubled individuals based on their social media usage patterns.

# LEARNING :

We can see that we can predict if the student is getting affected or student is facing problem while falling asleep or not based on the time they have spent on the individual social media apps.

Answer to our question 2: Yes, we can predict.

# TAKEAWAY :

As a key takeaway, the prevalence of high social media usage emerges as a significant factor contributing to various health issues. Individuals experiencing sleep deprivation, mood fluctuations, and diminished productivity are indicative of the adverse effects associated with prolonged social media exposure. This underscores the imperative for heightened awareness and proactive measures to mitigate the adverse impacts of excessive social media usage on mental and physical well-being.
